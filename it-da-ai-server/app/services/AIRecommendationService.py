"""
AI Recommendation Integration Service
GPT íŒŒì‹± â†’ DB ê²€ìƒ‰ â†’ AI ëª¨ë¸ ì¶”ì²œ í†µí•©
"""

import httpx
import math
import uuid
from collections import Counter
from typing import List, Dict, Optional

import numpy as np

from app.core.scoring_utils import match_from_percentile
from app.services.gpt_prompt_service import GPTPromptService
from app.models.model_loader import model_loader
from app.core.logging import logger


class AIRecommendationService:
    """AI ì¶”ì²œ í†µí•© ì„œë¹„ìŠ¤"""

    def __init__(
        self,
        gpt_service: GPTPromptService,
        spring_boot_url: str = "http://localhost:8080"
    ):
        self.gpt_service = gpt_service
        self.spring_boot_url = spring_boot_url

    # -------------------------
    # Normalizers (Spring Enum/DB ê°’ í˜¸í™˜)
    # -------------------------
    def _normalize_timeslot(self, ts: Optional[str]) -> Optional[str]:
        """Spring Enum: MORNING/AFTERNOON/EVENING/NIGHT"""
        if not ts:
            return None

        raw = str(ts).strip()

        # âœ… "MORNING,FLEXIBLE" ê°™ì€ ê°’ ë“¤ì–´ì˜¤ë©´ ì²« í† í°ë§Œ ì‚¬ìš©
        if "," in raw:
            raw = raw.split(",")[0].strip()

        lower = raw.lower()
        mapping = {
            "morning": "MORNING",
            "afternoon": "AFTERNOON",
            "evening": "EVENING",
            "night": "NIGHT",
            "ì˜¤ì „": "MORNING",
            "ì•„ì¹¨": "MORNING",
            "ì ì‹¬": "AFTERNOON",
            "ì˜¤í›„": "AFTERNOON",
            "ì €ë…": "EVENING",
            "ë°¤": "NIGHT",
            "ì•¼ê°„": "NIGHT",
        }
        return mapping.get(lower, raw.upper())

    def _normalize_location_type(self, lt: Optional[str]) -> Optional[str]:
        """Spring Enum: INDOOR/OUTDOOR"""
        if not lt:
            return None
        raw = str(lt).strip()
        lower = raw.lower()
        mapping = {
            "indoor": "INDOOR",
            "outdoor": "OUTDOOR",
            "ì‹¤ë‚´": "INDOOR",
            "ì‹¤ì™¸": "OUTDOOR",
            "ì•¼ì™¸": "OUTDOOR",
        }
        return mapping.get(lower, raw.upper())

    def _normalize_budget_for_model(self, bt: Optional[str]) -> str:
        """ëª¨ë¸ ì…ë ¥ì€ ì†Œë¬¸ìë¡œ í†µì¼ (value/quality)"""
        if not bt:
            return "value"
        raw = str(bt).strip()
        mapping = {
            "VALUE": "value", "value": "value", "ê°€ì„±ë¹„": "value", "í•©ë¦¬": "value",
            "QUALITY": "quality", "quality": "quality", "í’ˆì§ˆ": "quality",
        }
        return mapping.get(raw, mapping.get(raw.upper(), mapping.get(raw.lower(), "value")))

    # -------------------------
    # Intent (ë¬¸ì¥ ì˜ë„)
    # -------------------------
    def _detect_intent(self, user_prompt: str, parsed_query: dict) -> str:
        t = (user_prompt or "").lower()

        quiet_words = ["ì¡°ìš©", "ì‰¬", "íë§", "í¸í•˜ê²Œ", "ì—¬ìœ ", "ì¹´í˜", "ëŒ€í™”", "ì‚°ì±…", "ì „ì‹œ", "ë…ì„œ", "ì‰¬ê³ "]
        active_words = ["ëŸ¬ë‹", "ìš´ë™", "ë›°", "ë°°ë“œë¯¼í„´", "ì¶•êµ¬", "í—¬ìŠ¤", "ë“±ì‚°", "í´ë¼ì´ë°"]

        if any(w in t for w in quiet_words):
            return "QUIET"
        if any(w in t for w in active_words):
            return "ACTIVE"

        vibe = parsed_query.get("vibe")
        if vibe in ["íë§", "ì—¬ìœ ë¡œìš´"]:
            return "QUIET"
        return "NEUTRAL"

    def _apply_intent_adjustment(self, intent: str, meeting: dict) -> float:
        """
        match_scoreì— ë”í•´ì§€ëŠ” ë³´ì •ê°’.
        ë„ˆí¬ ì¹´í…Œê³ ë¦¬ ì²´ê³„ì— ë§ì¶° íŠœë‹í•˜ë©´ ë¨.
        """
        cat = (meeting.get("category") or "")
        sub = (meeting.get("subcategory") or "")

        if intent == "QUIET":
            # ìŠ¤í¬ì¸ ëŠ” ê°•í•˜ê²Œ íŒ¨ë„í‹°
            if cat == "ìŠ¤í¬ì¸ ":
                return -25.0
            # ì¡°ìš©í• ë§Œí•œ ê²ƒë“¤ ë³´ë„ˆìŠ¤(ë„ˆí¬ ë°ì´í„°ì— ë§ì¶° ìˆ˜ì •)
            if cat in ["ì¹´í˜", "ë¬¸í™”", "ì·¨ë¯¸"] or sub in ["ë…ì„œ", "ë³´ë“œê²Œì„", "ì „ì‹œ", "ìŠ¤í„°ë””"]:
                return +15.0

        if intent == "ACTIVE":
            if cat == "ìŠ¤í¬ì¸ ":
                return +15.0
            if cat in ["ì¹´í˜", "ë¬¸í™”"]:
                return -10.0

        return 0.0

    # -------------------------
    # Search payload builder (ì¤‘ìš”)
    # -------------------------
    def _should_apply_time_slot(self, q: dict) -> bool:
        # time_slotì€ ì¶”ì¸¡ì´ ì„ì´ë¯€ë¡œ confidence ë†’ì„ ë•Œë§Œ í•„í„°ë¡œ ì‚¬ìš©
        return q.get("time_slot") is not None and q.get("confidence", 0) >= 0.9

    def _should_apply_vibe(self, q: dict) -> bool:
        return q.get("vibe") is not None and q.get("confidence", 0) >= 0.9

    def _infer_location_type(self, q: dict) -> Optional[str]:
        kws = q.get("keywords") or []
        text = " ".join(kws)
        if "ì‹¤ë‚´" in text:
            return "INDOOR"
        if "ì•¼ì™¸" in text or "ì‹¤ì™¸" in text:
            return "OUTDOOR"
        return None

    def _to_spring_search_request(self, enriched_query: dict, user_ctx: dict) -> dict:
        raw_keywords = enriched_query.get("keywords") or []
        keywords = self._clean_keywords(raw_keywords)

        keyword = enriched_query.get("keyword")
        if not keyword and keywords:
            keyword = " ".join(keywords)

        # âœ… ìœ ì € ì¢Œí‘œ
        lat = user_ctx.get("lat") or user_ctx.get("latitude")
        lng = user_ctx.get("lng") or user_ctx.get("longitude")

        # âœ… locationQuery
        location_query = enriched_query.get("locationQuery") or enriched_query.get("location_query")

        # âœ… "ê·¼ì²˜/ì£¼ë³€/ì§‘" ì˜ë„
        near_me = self._is_near_me_phrase(location_query)

        # âœ… timeSlot: "ìœ ì € ì„ í˜¸" ì ˆëŒ€ ì„ì´ì§€ ì•Šê²Œ!
        # - enriched_queryì— timeSlotì´ ë“¤ì–´ê°€ë„ ë¬´ì‹œ(=enrich ë‹¨ê³„ì—ì„œ ì„ì˜€ì„ ìˆ˜ ìˆìŒ)
        conf = float(enriched_query.get("confidence", 0) or 0)
        gpt_ts = enriched_query.get("time_slot")  # ì˜¤ì§ snakeë§Œ ë³¸ë‹¤ (ì¤‘ìš”)
        time_slot = self._normalize_timeslot(gpt_ts) if (gpt_ts and conf >= 0.9) else None

        payload = {
            "category": enriched_query.get("category"),
            "subcategory": enriched_query.get("subcategory"),

            # âœ… GPT time_slotë§Œ, conf ë†’ì„ ë•Œë§Œ
            "timeSlot": time_slot,

            "vibe": enriched_query.get("vibe"),
            "keywords": keywords,

            # âœ… userLocationì€ í•­ìƒ ë³´ë‚´ë„ ë¨ (ê±°ë¦¬ ê³„ì‚°ìš©)
            "userLocation": {
                "latitude": lat,
                "longitude": lng
            },

            "locationQuery": location_query,
            "maxCost": enriched_query.get("maxCost") or enriched_query.get("max_cost"),
        }

        # âœ… radiusëŠ” â€œê·¼ì²˜ ì˜ë„ì¼ ë•Œë§Œâ€ í¬í•¨
        if near_me:
            payload["radius"] = float(enriched_query.get("radius") or 10.0)

        # ë¡œê·¸
        logger.info(
            f"[PAYLOAD] near_me={near_me} userLocation={payload.get('userLocation')} "
            f"radius={payload.get('radius', None)} timeSlot={payload.get('timeSlot')}"
        )
        logger.info(f"[PAYLOAD_KEYWORDS] raw={raw_keywords} -> cleaned={keywords}")

        # null/""/[] ì œê±°
        def clean(o):
            if isinstance(o, dict):
                return {k: clean(v) for k, v in o.items() if v is not None and v != "" and v != []}
            return o

        return clean(payload)

    # -------------------------
    # Step 4: candidate search + relaxation
    # -------------------------
    async def _search_meetings(self, enriched_query: dict, user_context: dict) -> list[dict]:
        try:
            payload = self._to_spring_search_request(enriched_query, user_context)
            logger.info(f"[PAYLOAD_FULL] {payload}")

            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(
                    f"{self.spring_boot_url}/api/meetings/search",
                    json=payload
                )

            if response.status_code == 200:
                result = response.json()
                return result.get("meetings", [])
            else:
                logger.warning(f"âš ï¸ ëª¨ì„ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code} body={response.text}")
                return []
        except Exception as e:
            logger.error(f"âš ï¸ ëª¨ì„ ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []

    from collections import Counter

    async def _search_with_relaxation(self, base_query: dict, user_context: dict, trace_steps: list) -> list[dict]:
        """
        - confidence ê¸°ë°˜ ì´ˆê¸° í•„í„° ê°•ë„ ì¡°ì ˆ
        - relax ìš°ì„ ìˆœìœ„: locationQuery -> vibe -> timeSlot -> keywords -> subcategory -> (ë§ˆì§€ë§‰) category
        - category ê°€ë“œ: categoryê°€ ìˆì—ˆëŠ”ë° ê²°ê³¼ê°€ ì „ë¶€ ë‹¤ë¥¸ categoryë©´ locationQuery ì œê±° í›„ category ê³ ì • ì¬ì‹œë„
        - trace_steps ìœ ì§€
        """

        conf = float(base_query.get("confidence", 0) or 0)

        def drop_keys(q: dict, *keys):
            qq = dict(q)
            for k in keys:
                qq.pop(k, None)
            return qq

        def norm(q: dict):
            # í‚¤ ì´ë¦„ í”ë“¤ë¦¼ ë°©ì§€ (ë„ˆ ì½”ë“œì— time_slot/timeSlot ì„ì—¬ìˆì–´ì„œ)
            qq = dict(q)
            if "time_slot" in qq and "timeSlot" not in qq:
                qq["timeSlot"] = qq.pop("time_slot")
            return qq

        async def _try(label: str, q: dict, level: int):
            q = norm(q)
            meetings = await self._search_meetings(q, user_context)
            meetings = meetings or []
            trace_steps.append({
                "level": level,
                "label": label,
                "payload": self._to_spring_search_request(q, user_context),
                "count": len(meetings),
                # ë””ë²„ê¹…ìš©(ì›í•˜ë©´ ì§€ì›Œë„ ë¨)
                "cats": dict(Counter((m.get("category"), m.get("subcategory")) for m in meetings)) if meetings else {},
            })
            return meetings

        base_cat = (base_query.get("category") or "").strip() or None

        # -----------------------
        # 1) conf ê¸°ë°˜ ì‹œì‘ ì¿¼ë¦¬ ì •ê·œí™”
        # -----------------------
        q0 = dict(base_query)

        # conf ë‚®ìœ¼ë©´ "ì„¸ë¶€"ë§Œ ë¯¸ë¦¬ ëºŒ (category/locationì€ ê±´ë“œë¦¬ì§€ ë§ˆ!)
        if conf < 0.70:
            q0 = drop_keys(q0, "subcategory")
        if conf < 0.85:
            q0 = drop_keys(q0, "vibe", "time_slot", "timeSlot")

        # âœ… L0
        cands = await _try("L0(conf ë°˜ì˜)", q0, 0)
        if cands:
            # category ê°€ë“œ: ì›í•˜ëŠ” categoryê°€ ìˆì—ˆëŠ”ë° ê²°ê³¼ê°€ ì „ë¶€ ë‹¤ë¥¸ categoryë©´ ì¬ì‹œë„
            if base_cat and all((m.get("category") or "").strip() != base_cat for m in cands):
                q_fix = drop_keys(q0, "location_query", "locationQuery")  # ì§€ì—­ ë²„ë¦¬ê³  category ìœ ì§€
                c2 = await _try("L0-guard(location ì œê±°, category ìœ ì§€)", q_fix, 1)
                if c2:
                    return c2
            return cands

        # -----------------------
        # 2) relax plan (ìš”ì²­ ìˆ˜ ì»¨íŠ¸ë¡¤)
        # -----------------------
        # í•µì‹¬: categoryëŠ” ë§¨ ë§ˆì§€ë§‰
        # locationQuery(ì§€ì—­) -> vibe -> timeSlot -> keywords -> subcategory -> category
        if conf >= 0.90:
            plans = [
                ("L1 locationQuery ì œê±°", ("location_query", "locationQuery")),
                ("L2 vibe ì œê±°", ("vibe",)),
                ("L3 timeSlot ì œê±°", ("time_slot", "timeSlot")),
                ("L4 keywords ì œê±°", ("keywords",)),
                ("L5 subcategory ì œê±°", ("subcategory",)),
                ("L6 category ì œê±°", ("category",)),
            ]
        elif conf >= 0.75:
            plans = [
                ("L1 locationQuery ì œê±°", ("location_query", "locationQuery")),
                ("L2 timeSlot ì œê±°", ("time_slot", "timeSlot")),
                ("L3 subcategory ì œê±°", ("subcategory",)),
                ("L4 keywords ì œê±°", ("keywords",)),
                ("L5 category ì œê±°", ("category",)),
            ]
        else:
            # ë‚®ì€ conf: ì´ë¯¸ ë„“ê²Œ ì‹œì‘í–ˆìœ¼ë‹ˆ 2~3ë²ˆë§Œ
            plans = [
                ("L1 locationQuery ì œê±°", ("location_query", "locationQuery")),
                ("L2 keywords ì œê±°", ("keywords",)),
                ("L3 category ì œê±°", ("category",)),
            ]

        # -----------------------
        # 3) relax ìˆœì°¨ ìˆ˜í–‰ + category ê°€ë“œ
        # -----------------------
        current = dict(q0)
        level = 1
        for label, keys in plans:
            qn = drop_keys(current, *keys)
            cands = await _try(label, qn, level)

            if cands:
                # category ê°€ë“œ: base_catì´ ìˆëŠ”ë° ê²°ê³¼ê°€ ì „ë¶€ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë©´ "ì§€ì—­ ì œê±° + category ìœ ì§€" í•œë²ˆ ë”
                if base_cat and all((m.get("category") or "").strip() != base_cat for m in cands):
                    q_fix = drop_keys(qn, "location_query", "locationQuery")  # ì§€ì—­ ë²„ë¦¬ê³  category ìœ ì§€
                    c2 = await _try(f"{label}-guard(location ì œê±°, category ìœ ì§€)", q_fix, level + 1)
                    if c2:
                        return c2
                return cands

            current = qn
            level += 1

        return []

    # -------------------------
    # Main pipeline
    # -------------------------
    async def get_ai_recommendations(self, user_prompt: str, user_id: int, top_n: int = 5) -> Dict:
        rid = str(uuid.uuid4())[:8]
        logger.info(f"[RID={rid}] ğŸ” AI ê²€ìƒ‰ ìš”ì²­: user_id={user_id}, prompt='{user_prompt}'")

        try:
            # Step 1
            logger.info(f"[Step 1] GPT í”„ë¡¬í”„íŠ¸ íŒŒì‹±: {user_prompt}")
            parsed_query = await self.gpt_service.parse_search_query(user_prompt)

            # Step 2
            logger.info(f"[Step 2] ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ: user_id={user_id}")
            user_context = await self._get_user_context(user_id)
            logger.info(f"[CTX] lat={user_context.get('latitude')} lng={user_context.get('longitude')}")

            kw = parsed_query.get("keywords") or []
            conf = float(parsed_query.get("confidence", 0) or 0)
            cat = parsed_query.get("category")
            sub = parsed_query.get("subcategory")
            vibe = parsed_query.get("vibe")
            ts = parsed_query.get("time_slot")

            # âœ… ì •ë³´ ê±°ì˜ ì—†ëŠ” ì…ë ¥(ì˜ˆ: "ì§‘ì—ì„œ", "ê·¸ëƒ¥", "ì¶”ì²œ") ë°©ì§€
            if conf < 0.6 and len(kw) == 0 and not cat and not sub and not vibe and not ts:
                card = self._make_clarification_card(user_prompt, parsed_query, user_context)
                return {
                    "user_prompt": user_prompt,
                    "parsed_query": parsed_query,
                    "total_candidates": 0,
                    "recommendations": [card],
                    "search_trace": {
                        "steps": [],
                        "final_level": 0,
                        "final_label": "EARLY_CLARIFY",
                        "fallback": False
                    }
                }

            # Step 3
            enriched_query = await self.gpt_service.enrich_with_user_context(parsed_query, user_context)

            # Step 4
            trace_steps: list = []

            # âœ… L0ë¥¼ ë¯¸ë¦¬ ì™„í™”í•´ì„œ ì‹œë„ íšŸìˆ˜ë¥¼ ì¤„ì„
            base_query = self._pre_relax_query_by_conf(enriched_query)

            candidate_meetings = await self._search_with_relaxation(base_query, user_context, trace_steps)

            if not candidate_meetings:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - SVD ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
                data = await self._fallback_svd_recommendation(user_id, user_prompt, parsed_query, top_n, user_context)


                # fallbackë„ intent ë³´ì •
                intent = self._detect_intent(user_prompt, parsed_query)

                for rec in data.get("recommendations", []):
                    rec["match_score"] = int(max(0, min(100, rec.get("match_score", 0) + self._apply_intent_adjustment(intent, rec))))
                    rec["intent"] = intent

                data["search_trace"] = {
                    "steps": trace_steps,
                    "final_level": trace_steps[-1]["level"] if trace_steps else 0,
                    "final_label": trace_steps[-1]["label"] if trace_steps else "L0 ì›ë³¸",
                    "fallback": True
                }
                return data


            logger.info(f"[Step 5] AI ì ìˆ˜ ê³„ì‚°: {len(candidate_meetings)}ê°œ ëª¨ì„")

            intent = self._detect_intent(user_prompt, parsed_query)  # âœ… ë¨¼ì € ë§Œë“¤ê³ 

            scored_meetings = await self._score_meetings(
                user_id, user_context, candidate_meetings, parsed_query, intent
            )

            # âœ… intent ë³´ì •(ë£° ê¸°ë°˜)
            for m in scored_meetings:
                m["match_score"] = int(max(0, min(100, m["match_score"] + self._apply_intent_adjustment(intent, m))))
                m["intent"] = intent



            # Step 6
            top_recommendations = sorted(scored_meetings, key=lambda x: x["match_score"], reverse=True)[:top_n]

            # Step 7
            for rec in top_recommendations:
                if (not parsed_query.get("keywords")) or parsed_query.get("confidence", 0) < 0.6:
                    rec["reasoning"] = self._fallback_reasoning(rec, parsed_query)
                else:
                    rec["reasoning"] = await self._generate_reasoning(user_context, rec, parsed_query)

            return {
                "user_prompt": user_prompt,
                "parsed_query": parsed_query,
                "total_candidates": len(candidate_meetings),
                "recommendations": top_recommendations,
                "search_trace": {
                    "steps": trace_steps,
                    "final_level": trace_steps[-1]["level"] if trace_steps else 0,
                    "final_label": trace_steps[-1]["label"] if trace_steps else "L0 ì›ë³¸",
                    "fallback": False
                }
            }

        except Exception as e:
            logger.error(f"âŒ AI ì¶”ì²œ ì‹¤íŒ¨: {e}")
            raise

    # -------------------------
    # Scoring (ë„ˆ ì½”ë“œ ê±°ì˜ ê·¸ëŒ€ë¡œ)
    # -------------------------
    # AIRecommendationService ì•ˆì— ìˆëŠ” _score_meetings()ë¥¼ ì´ ë²„ì „ìœ¼ë¡œ êµì²´í•˜ë©´ ë¨.
    # - /search ë­í‚¹: rankerë¡œ match_score ë§Œë“¤ê³  ì •ë ¬
    # - UIìš© predicted_rating: (ì„ íƒ) regressorë¡œ ê°™ì´ ë„£ì–´ì¤Œ
    # - ê¸°ì¡´ key_points ìœ ì§€

    async def _score_meetings(
            self,
            user_id: int,
            user_context: dict,
            candidate_meetings: list[dict],
            parsed_query: dict,
            intent: str,
    ) -> list[dict]:
        def pick(d: dict, *keys, default=None):
            for k in keys:
                if k in d and d.get(k) is not None:
                    return d.get(k)
            return default

        if not model_loader.ranker or not model_loader.ranker.is_loaded():
            raise RuntimeError("LightGBM Ranker ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not model_loader.feature_builder:
            raise RuntimeError("FeatureBuilderê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        use_regressor_for_rating = bool(model_loader.regressor and model_loader.regressor.is_loaded())

        # âœ… confidence (0~1)
        conf = float(parsed_query.get("confidence", 0) or 0)

        def dynamic_ceil(n: int, conf: float) -> int:
            # í›„ë³´ ìˆ˜ê°€ ì ì„ìˆ˜ë¡ ìƒí•œì´ ë‚®ì•„ì•¼ "ê·¸ëŸ´ë“¯"
            if n <= 2:
                base = 78
            elif n == 3:
                base = 82
            elif n <= 5:
                base = 86
            elif n <= 10:
                base = 90
            else:
                base = 92

            # confidence ë‚®ì„ìˆ˜ë¡ ìƒí•œ ê¹ê¸° (ìµœëŒ€ 12ì  ì •ë„)
            penalty = int(round((1.0 - max(0.0, min(1.0, conf))) * 12))
            return max(70, base - penalty)

        user = {
            "lat": pick(user_context, "lat", "latitude", default=None),
            "lng": pick(user_context, "lng", "longitude", default=None),
            "interests": pick(user_context, "interests", default=""),
            "time_preference": self._normalize_timeslot(
                pick(user_context, "time_preference", "timePreference", default=None)
            ),
            "user_location_pref": pick(user_context, "user_location_pref", "userLocationPref", default=None),
            "budget_type": self._normalize_budget_for_model(
                pick(user_context, "budget_type", "budgetType", default="value")
            ),
            "user_avg_rating": float(pick(user_context, "user_avg_rating", "userAvgRating", default=3.0)),
            "user_meeting_count": int(pick(user_context, "user_meeting_count", "userMeetingCount", default=0)),
            "user_rating_std": float(pick(user_context, "user_rating_std", "userRatingStd", default=0.5)),
        }

        rows, feats, valid_candidates = [], [], []
        for raw in candidate_meetings:
            try:
                m = self._normalize_meeting(raw)
                feat, x = model_loader.feature_builder.build(user, m)
                rows.append(x[0])
                feats.append(feat)
                valid_candidates.append(m)
            except Exception as e:
                logger.warning(f"âš ï¸ feature build ì‹¤íŒ¨ meeting_id={raw.get('meeting_id')}: {e}")
                continue

        if not rows:
            return []

        X = np.vstack(rows)

        # 1) ranker raw
        rank_raw = model_loader.ranker.predict(X)
        raw_list = [float(v) for v in rank_raw]
        n = len(raw_list)

        # âœ… ë™ì  ìƒí•œ
        ceil = dynamic_ceil(n, conf)

        # 2) optional rating
        rating_list = None
        if use_regressor_for_rating:
            try:
                preds = model_loader.regressor.predict(X)
                rating_list = [float(v) for v in preds]
            except Exception as e:
                logger.warning(f"âš ï¸ regressor rating ì˜ˆì¸¡ ì‹¤íŒ¨. rating ì—†ì´ ì§„í–‰: {e}")
                rating_list = None

        # 3) match_score ê³„ì‚°
        match_scores = [55] * n

        if n <= 10:
            # âœ… ì†Œìˆ˜ í›„ë³´ëŠ” "ë“±ìˆ˜ + raw ê°„ê²©" ê¸°ë°˜ (100% ë°©ì§€)
            base = [90, 84, 79, 74, 69, 65, 62, 60, 58, 56]
            order = sorted(range(n), key=lambda i: raw_list[i], reverse=True)

            top = raw_list[order[0]]
            bottom = raw_list[order[-1]]
            span = (top - bottom) if (top - bottom) != 0 else 1.0

            for rank, i in enumerate(order):
                b = base[rank] if rank < len(base) else 55

                # top=1, bottom=0
                t = (raw_list[i] - bottom) / span

                # -3 ~ +3 ì •ë„ë§Œ í”ë“¤ì–´ì£¼ê¸°
                adj = (t - 0.5) * 6.0

                ms = b + adj

                # ë°”ë‹¥/ìƒí•œ ê¸°ë³¸ ìº¡
                ms = max(52, min(92, ms))

                # âœ… confidence+n ê¸°ë°˜ ë™ì  ìƒí•œ ì ìš©
                ms = min(ms, ceil)

                match_scores[i] = int(round(ms))

        else:
            # í›„ë³´ ë§ìœ¼ë©´ percentile ê¸°ë°˜
            sorted_vals = sorted(raw_list)

            def percentile_midrank(x: float) -> float:
                lt = 0
                eq = 0
                for v in sorted_vals:
                    if v < x:
                        lt += 1
                    elif v == x:
                        eq += 1
                p = (lt + 0.5 * eq) / n
                eps = 0.5 / n
                if p < eps:
                    p = eps
                if p > 1 - eps:
                    p = 1 - eps
                return p

            for i, s in enumerate(raw_list):
                p = percentile_midrank(float(s))  # 0~1
                p = max(0.0, min(1.0, 0.5 + (p - 0.5) * 2.0))  # stretch ì•½í•˜ê²Œ

                ms = match_from_percentile(p, floor=52, ceil=92, gamma=1.5)
                ms = min(ms, ceil)  # âœ… ë™ì  ìƒí•œ
                match_scores[i] = int(ms)

        # 4) ê²°ê³¼ êµ¬ì„±
        results = []
        for idx, (m, feat, s) in enumerate(zip(valid_candidates, feats, raw_list)):
            ms = int(match_scores[idx])

            if ms >= 88:
                lvl = "VERY_HIGH"
            elif ms >= 80:
                lvl = "HIGH"
            elif ms >= 65:
                lvl = "MEDIUM"
            else:
                lvl = "LOW"

            item = {
                **m,
                "rank_raw": round(float(s), 4),
                "match_score": ms,
                "match_level": lvl,
                "key_points": self._build_key_points_from_feat(feat),
                "score_meta": {
                    "n_candidates": n,
                    "confidence": round(conf, 3),
                    "ceil": int(ceil),
                }
            }

            if rating_list is not None:
                item["predicted_rating"] = round(float(rating_list[idx]), 3)

            results.append(item)

        results.sort(key=lambda x: x.get("match_score", 0), reverse=True)
        return results

    def _build_key_points_from_feat(self, feat: dict) -> list[str]:
        points = []
        if feat.get("distance_km", 999) <= 3:
            points.append(f"ê°€ê¹Œìš´ ê±°ë¦¬({feat['distance_km']:.1f}km)")
        if feat.get("time_match") == 1.0:
            points.append("ì„ í˜¸ ì‹œê°„ëŒ€ ì¼ì¹˜")
        if feat.get("location_type_match") == 1.0:
            points.append("ì‹¤ë‚´/ì•¼ì™¸ ì„ í˜¸ ì¼ì¹˜")
        if feat.get("cost_match_score", 0) >= 0.7:
            points.append("ì˜ˆì‚°ì— ì˜ ë§ìŒ")
        if feat.get("interest_match_score", 0) >= 0.5:
            points.append("ê´€ì‹¬ì‚¬ ë§¤ì¹­")
        return points[:3]

    # -------------------------
    # User context / Reasoning / Fallback / Batch
    # -------------------------
    async def _get_user_context(self, user_id: int) -> Dict:
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.spring_boot_url}/api/users/{user_id}/context")
                response.raise_for_status()
                ctx = response.json()
                logger.info(f"âœ… ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì„±ê³µ: userId={user_id}")
                return ctx
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "user_id": user_id,
                "latitude": 37.5665,
                "longitude": 126.9780,
                "interests": "",
                "time_preference": "",
                "budget_type": "VALUE",
                "user_avg_rating": 0.0,
                "user_meeting_count": 0,
                "user_rating_std": 0.0
            }

    async def _generate_reasoning(self, user_context: Dict, meeting: Dict, parsed_query: Dict) -> str:
        """
        GPTë¥¼ í™œìš©í•œ ë™ì ì´ê³  ê³µê° ê°€ëŠ¥í•œ ì¶”ì²œ ì´ìœ  ìƒì„±
        """
        try:
            # âœ… None ì²´í¬ë¥¼ í¬í•¨í•œ ì•ˆì „í•œ ê°’ ì¶”ì¶œ
            user_prompt_keywords = " ".join(parsed_query.get("keywords", []))
            category = meeting.get("category") or ""
            subcategory = meeting.get("subcategory") or ""
            location = meeting.get("location_name") or "ë¯¸ì •"
            distance = meeting.get("distance_km") if meeting.get("distance_km") is not None else 0
            cost = meeting.get("expected_cost") if meeting.get("expected_cost") is not None else 0
            participants = meeting.get("current_participants") if meeting.get("current_participants") is not None else 0
            max_participants = meeting.get("max_participants") if meeting.get("max_participants") is not None else 10
            vibe = meeting.get("vibe") or ""

            # âœ… GPT í”„ë¡¬í”„íŠ¸
            prompt = f"""
    ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ AI ì¶”ì²œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ê°ì •ì„ ì´í•´í•˜ê³ , ì™œ ì´ ëª¨ì„ì´ ë”± ë§ëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.

    **ì‚¬ìš©ì í‚¤ì›Œë“œ:** {user_prompt_keywords}

    **ì¶”ì²œ ëª¨ì„:**
    - ì œëª©: {meeting.get('title', 'ì œëª© ì—†ìŒ')}
    - ì¹´í…Œê³ ë¦¬: {category} - {subcategory}
    - ë¶„ìœ„ê¸°: {vibe}
    - ìœ„ì¹˜: {location} ({distance:.1f}km)
    - ë¹„ìš©: {cost:,}ì›
    - ì°¸ê°€ì: {participants}/{max_participants}ëª…

    **ì‘ì„± ê·œì¹™:**
    1. ì‚¬ìš©ìì˜ ê°ì •/ìƒí™©ì— ê³µê°í•˜ëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘
    2. ì´ ëª¨ì„ì˜ ë§¤ë ¥ í¬ì¸íŠ¸ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
    3. ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ (ì¡´ëŒ“ë§ + ë°˜ë§ ì„ì–´ì„œ)
    4. ì´ëª¨ì§€ 1-2ê°œë§Œ ì‚¬ìš© (ê³¼í•˜ì§€ ì•Šê²Œ)
    5. ì´ 3-4ë¬¸ì¥, 80-120ì ì´ë‚´

    **ì¢‹ì€ ì˜ˆì‹œ:**
    - "ì˜¤ëŠ˜ í˜ë“œì…¨ì£ ? ğŸ˜Š ì¡°ìš©í•œ ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜ ë¨¹ìœ¼ë©´ì„œ ë¨¸ë¦¬ ì¢€ ì‹íˆëŠ” ê±´ ì–´ë–¨ê¹Œìš”? í™ëŒ€ ì¹´í˜ëŠ” ë¶„ìœ„ê¸°ë„ ì•„ëŠ‘í•˜ê³  2.3km ê±°ë¦¬ë¼ ë¶€ë‹´ ì—†ì–´ìš”!"
    - "ë”± ì ë‹¹íˆ ëª¸ í’€ê³  ì‹¶ì„ ë•Œë„¤ìš”! ğŸƒ í•œê°•ì—ì„œ 5km ê°€ë³ê²Œ ë›°ë©´ì„œ ê°™ì´ ë‹¬ë¦¬ëŠ” ì‚¬ëŒë“¤ì´ë‘ ìˆ˜ë‹¤ë„ ë–¨ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ í™• í’€ë ¤ìš”."
    - "ê¸°ë¶„ì „í™˜ì—” ì „ì‹œíšŒë§Œ í•œ ê²Œ ì—†ì£ ! ğŸ¨ ì„±ìˆ˜ë™ ê°¤ëŸ¬ë¦¬ëŠ” ë¬´ë£Œ ì…ì¥ì´ê³  ì‘í’ˆ ë³´ë©´ì„œ ê°ì„± ì¶©ì „í•˜ê¸° ë”±ì´ì—ìš”."

    **ì´ì œ ì‘ì„±í•˜ì„¸ìš” (ì¶”ì²œ ì´ìœ ë§Œ, ë‹¤ë¥¸ ë§ ì—†ì´):**
    """

            # âœ… await ì œê±° - ë™ê¸° í˜¸ì¶œ
            response = self.gpt_service.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ AI ì¶”ì²œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=200
            )

            reasoning = response.choices[0].message.content.strip()
            logger.info(f"âœ… GPT reasoning ìƒì„±: {reasoning[:50]}...")
            return reasoning

        except Exception as e:
            logger.error(f"âš ï¸ GPT reasoning ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            return self._fallback_reasoning(meeting, parsed_query)

    def _fallback_reasoning(self, meeting: Dict, parsed_query: Dict) -> str:
        """GPT ì‹¤íŒ¨ ì‹œ í…œí”Œë¦¿ ê¸°ë°˜ reasoning"""

        # âœ… None ì²´í¬ë¥¼ í¬í•¨í•œ ì•ˆì „í•œ ê°’ ì¶”ì¶œ
        category = meeting.get("category") or ""
        subcategory = meeting.get("subcategory") or ""
        location = meeting.get("location_name") or "ë¯¸ì •"
        distance = meeting.get("distance_km") if meeting.get("distance_km") is not None else 0
        cost = meeting.get("expected_cost") if meeting.get("expected_cost") is not None else 0
        participants = meeting.get("current_participants") if meeting.get("current_participants") is not None else 0

        templates = {
            "ì¹´í˜": [
                f"ì¡°ìš©í•œ {location}ì—ì„œ íë§ íƒ€ì„ ì–´ë•Œìš”? â˜• {distance:.1f}km ê±°ë¦¬ë¼ ë¶€ë‹´ ì—†ì´ ë‹¤ë…€ì˜¬ ìˆ˜ ìˆì–´ìš”!",
                f"ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜ ë¨¹ìœ¼ë©´ì„œ ì—¬ìœ ë¡­ê²Œ ì‰¬ëŠ” ê±´ ì–´ë–¨ê¹Œìš”? í˜„ì¬ {participants}ëª…ì´ ì°¸ì—¬ ì¤‘ì´ë¼ í¸ì•ˆí•œ ë¶„ìœ„ê¸°ì˜ˆìš”.",
            ],
            "ìŠ¤í¬ì¸ ": [
                f"ê°€ë³ê²Œ ëª¸ í’€ë©´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë‚ ë ¤ë²„ë¦¬ê¸° ì¢‹ì•„ìš”! ğŸƒ {location}ì—ì„œ í•¨ê»˜ ìš´ë™í•˜ë©´ ë” ì¬ë°Œì–´ìš”.",
                f"ì ë‹¹íˆ ë•€ í˜ë¦¬ë©´ì„œ ê¸°ë¶„ì „í™˜í•˜ê¸° ë”±! {participants}ëª…ì´ë‘ ê°™ì´ í•˜ë©´ ë™ê¸°ë¶€ì—¬ë„ ë˜ê³ ìš”.",
            ],
            "ë§›ì§‘": [
                f"ë§›ìˆëŠ” ê±° ë¨¹ìœ¼ë©´ì„œ íë§í•˜ëŠ” ê²Œ ìµœê³ ì£ ! ğŸ½ï¸ {subcategory} ì¢‹ì•„í•˜ì‹œë©´ ê°•ì¶”ì˜ˆìš”.",
                f"{cost:,}ì›ìœ¼ë¡œ ë§›ìˆëŠ” ìŒì‹ ë¨¹ìœ¼ë©´ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ í’€ ìˆ˜ ìˆì–´ìš”!",
            ],
            "ë¬¸í™”ì˜ˆìˆ ": [
                f"ê°ì„± ì¶©ì „ì´ í•„ìš”í•  ë•Œ! ğŸ¨ {location}ì—ì„œ ì—¬ìœ ë¡­ê²Œ ì˜ˆìˆ  ê°ìƒí•˜ë©´ ë§ˆìŒì´ í¸ì•ˆí•´ì ¸ìš”.",
                f"ì¡°ìš©íˆ ì „ì‹œ ë³´ë©´ì„œ ë¨¸ë¦¬ ë¹„ìš°ê¸° ë”± ì¢‹ì€ ëª¨ì„ì´ì—ìš”. {distance:.1f}km ê±°ë¦¬ë¼ ê°€ê¹ê³ ìš”.",
            ],
            "ì†Œì…œ": [
                f"ê°€ë³ê²Œ ë†€ë©´ì„œ ê¸°ë¶„ì „í™˜! ğŸ® {subcategory} í•˜ë©´ì„œ ì›ƒë‹¤ ë³´ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ í™• í’€ë ¤ìš”.",
                f"{participants}ëª…ì´ë‘ í•¨ê»˜í•˜ëŠ” {subcategory} ëª¨ì„! ë¶€ë‹´ ì—†ì´ ì¦ê¸°ê¸° ì¢‹ì•„ìš”.",
            ],
        }

        import random
        options = templates.get(category, [f"ì´ ëª¨ì„ì€ ë‹¹ì‹ ì˜ ì·¨í–¥ê³¼ ì˜ ë§ì„ ê²ƒ ê°™ì•„ìš”! ğŸ˜Š {location}ì—ì„œ {distance:.1f}km ê±°ë¦¬ì˜ˆìš”."])
        return random.choice(options)

    async def _fallback_svd_recommendation(
            self,
            user_id: int,
            user_prompt: str,
            parsed_query: Dict,
            top_n: int,
            user_context: Dict,  # âœ… ì¶”ê°€
    ) -> Dict:
        if not model_loader.svd or not model_loader.svd.is_loaded():
            raise RuntimeError("SVD ëª¨ë¸ ë¡œë“œë˜ì§€ ì•ŠìŒ")

        svd_recommendations = await model_loader.svd.recommend(user_id=user_id, top_n=top_n * 2)
        meeting_ids = [int(mid) for mid, _ in svd_recommendations]
        meetings = await self._get_meetings_by_ids(meeting_ids)

        # âœ… fallbackì—ì„œë„ ìœ ì €ì¢Œí‘œ ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚° ì£¼ì…
        meetings = self._inject_distance_km(meetings, user_context)

        scored = []
        for meeting in meetings:
            # meeting_id í‚¤ í˜¼ìš© ëŒ€ì‘
            m_id = meeting.get("meeting_id") or meeting.get("meetingId")
            svd_score = next((score for mid, score in svd_recommendations if int(mid) == int(m_id)), 3.5)

            scored.append({
                **meeting,
                "match_score": min(100, int(float(svd_score) * 20)),
                "predicted_rating": round(float(svd_score), 1),
                "svd_score": round(float(svd_score), 2),
                "key_points": ["SVD í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ"],
                "reasoning": "ê³¼ê±° ì°¸ì—¬ ì´ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œëœ ëª¨ì„ì…ë‹ˆë‹¤."
            })

        return {
            "user_prompt": user_prompt,
            "parsed_query": parsed_query,
            "total_candidates": len(scored),
            "recommendations": scored[:top_n],
            "fallback": True
        }

    async def _get_meetings_by_ids(self, meeting_ids: List[int]) -> List[Dict]:
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(
                    f"{self.spring_boot_url}/api/meetings/batch",
                    json={"meetingIds": meeting_ids}
                )
            if response.status_code == 200:
                return response.json().get("meetings", [])
            return []
        except Exception as e:
            logger.error(f"âš ï¸ ëª¨ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _normalize_meeting(self, m: dict) -> dict:
        """
        Spring ì‘ë‹µ(snake/camel í˜¼ìš©) â†’ FeatureBuilder ì…ë ¥ í‘œì¤€í™”
        + UI ìœ ì§€ í•„ë“œ(title,image_url) í¬í•¨
        """
        return {
            "meeting_id": m.get("meeting_id") or m.get("meetingId"),

            "lat": m.get("latitude") or m.get("lat"),
            "lng": m.get("longitude") or m.get("lng"),

            "category": m.get("category", "") or "",
            "subcategory": m.get("subcategory", "") or "",

            "time_slot": self._normalize_timeslot(m.get("time_slot") or m.get("timeSlot")),
            "meeting_location_type": self._normalize_location_type(m.get("location_type") or m.get("locationType")),
            "vibe": m.get("vibe", "") or "",

            "max_participants": m.get("max_participants") or m.get("maxParticipants") or 10,
            "meeting_participant_count": m.get("current_participants") or m.get("currentParticipants") or 0,
            "expected_cost": m.get("expected_cost") or m.get("expectedCost") or 0,

            "meeting_avg_rating": m.get("avg_rating") or m.get("avgRating") or 0.0,
            "meeting_rating_count": m.get("rating_count") or m.get("ratingCount") or 0,

            "distance_km": m.get("distance_km") or m.get("distanceKm"),

            # UIìš© ë³´ì¡´
            "title": m.get("title"),
            "image_url": m.get("image_url") or m.get("imageUrl"),
            "location_name": m.get("location_name") or m.get("locationName"),
            "location_address": m.get("location_address") or m.get("locationAddress"),
            "meeting_time": m.get("meeting_time") or m.get("meetingTime"),
            "current_participants": m.get("current_participants") or m.get("currentParticipants"),
            "max_participants": m.get("max_participants") or m.get("maxParticipants"),
        }

    def _make_clarification_card(self, user_prompt: str, parsed_query: dict, user_context: dict) -> dict:
        # ìœ ì € ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ â€œì§‘ ê·¼ì²˜â€ ê°™ì€ ë¬¸êµ¬ë„ ê°€ëŠ¥
        # (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¡œë§Œ)
        return {
            "meeting_id": -1,
            "title": "ì–´ë–¤ ê±¸ í•˜ê³  ì‹¶ì€ì§€ í•œ ê°€ì§€ë§Œ ë” ì•Œë ¤ì¤˜ìš” ğŸ™‚",
            "category": "SYSTEM",
            "subcategory": "CLARIFY",
            "location_name": "ì¶”ì²œì„ ìœ„í•´ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•´ìš”",
            "image_url": None,

            "match_score": 0,
            "match_level": "INFO",
            "predicted_rating": None,

            "key_points": [
                "ì˜ˆ: ì§‘ì—ì„œ ìš”ë¦¬ ê°™ì´ í•˜ê¸°",
                "ì˜ˆ: ì§‘ì—ì„œ ìŠ¤í„°ë””/ê³µë¶€",
                "ì˜ˆ: ì§‘ ê·¼ì²˜ ì¹´í˜ì—ì„œ ë¸ŒëŸ°ì¹˜",
            ],
            "reasoning": (
                f"ì§€ê¸ˆ ì…ë ¥ì€ '{user_prompt}'ë¼ì„œ ì¶”ì²œ ë²”ìœ„ë¥¼ ì¢íˆê¸° ì–´ë ¤ì›Œìš”. "
                "ì›í•˜ëŠ” í™œë™(ìš”ë¦¬/ìŠ¤í„°ë””/ì˜í™”/ìš´ë™ ë“±)ì´ë‚˜ ì§€ì—­(í™ëŒ€/ì„±ìˆ˜ ë“±) ì¤‘ 1ê°œë§Œ ë” ë§í•´ì¤˜ìš”!"
            ),
            "is_clarification": True,
            "intent": "NEUTRAL",
        }

    def _pre_relax_query_by_conf(self, q: dict) -> dict:
        """
        L0 ìì²´ë¥¼ confidence ê¸°ë°˜ìœ¼ë¡œ ì™„í™”í•´ì„œ,
        relaxation ë‹¨ê³„ê°€ ê³¼ë„í•˜ê²Œ ì—¬ëŸ¬ ë²ˆ ëŒì§€ ì•Šê²Œ í•¨.
        """
        conf = float(q.get("confidence", 0) or 0)
        qq = dict(q)

        # 0.7 ë¯¸ë§Œì´ë©´ subcategoryëŠ” ë„ˆë¬´ ê³µê²©ì  â†’ L0ì—ì„œ ì œê±°
        if conf < 0.7:
            qq.pop("subcategory", None)

        # 0.6 ë¯¸ë§Œì´ë©´ vibeëŠ” ì œê±°
        if conf < 0.6:
            qq.pop("vibe", None)

        # time_slotì€ ë„ˆê°€ ì´ë¯¸ 0.9 ì´ìƒì¼ ë•Œë§Œ ì“°ê¸°ë¡œ í–ˆìœ¼ë‹ˆ ìœ ì§€
        if conf < 0.9:
            qq.pop("time_slot", None)
            qq.pop("timeSlot", None)

        # 0.45 ë¯¸ë§Œì´ë©´ categoryë„ ì œê±°í•˜ê³  keyword ìœ„ì£¼ë¡œ ë„“ê²Œ
        if conf < 0.45:
            qq.pop("category", None)

        return qq

    # -------------------------
    # Distance utils (fallbackì—ì„œë„ ê±°ë¦¬ ê³„ì‚°)
    # -------------------------
    def _haversine_km(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """ë‘ ì¢Œí‘œ ê°„ ê±°ë¦¬(km)."""
        R = 6371.0
        p1, p2 = math.radians(lat1), math.radians(lat2)
        d1 = math.radians(lat2 - lat1)
        d2 = math.radians(lon2 - lon1)
        a = (math.sin(d1 / 2) ** 2) + math.cos(p1) * math.cos(p2) * (math.sin(d2 / 2) ** 2)
        return 2 * R * math.asin(math.sqrt(a))

    def _inject_distance_km(self, meetings: List[Dict], user_ctx: Dict) -> List[Dict]:
        """meetingsì— distance_kmì´ ì—†ìœ¼ë©´ ìœ ì €ì¢Œí‘œë¡œ ê³„ì‚°í•´ì„œ ë„£ì–´ì¤Œ."""
        u_lat = user_ctx.get("latitude") or user_ctx.get("lat")
        u_lng = user_ctx.get("longitude") or user_ctx.get("lng")

        if u_lat is None or u_lng is None:
            return meetings

        out = []
        for m in meetings or []:
            # ì´ë¯¸ springì—ì„œ ë‚´ë ¤ì¤€ distanceê°€ ìˆìœ¼ë©´ ìœ ì§€
            if m.get("distance_km") is not None or m.get("distanceKm") is not None:
                out.append(m)
                continue

            m_lat = m.get("latitude") or m.get("lat")
            m_lng = m.get("longitude") or m.get("lng")

            if m_lat is None or m_lng is None:
                out.append(m)
                continue

            try:
                d = self._haversine_km(float(u_lat), float(u_lng), float(m_lat), float(m_lng))
                mm = dict(m)
                mm["distance_km"] = round(float(d), 3)  # UIëŠ” 0.1ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë³´ì—¬ì£¼ë©´ ë¨
                out.append(mm)
            except Exception:
                out.append(m)

        return out

    def _clean_keywords(self, keywords: Optional[list[str]]) -> list[str]:
        if not keywords:
            return []

        stop = {
            "í•˜ê³ ì‹¶ì–´", "í•˜ê³ ", "ì‹¶ì–´", "ì›í•´", "ì¶”ì²œ", "í•´ì£¼ì„¸ìš”", "í•´ì¤˜",
            "ê·¸ëƒ¥", "ì¢€", "í•œë²ˆ", "ê°™ì´",
            "ë°–ì—ì„œ", "ì§‘ì—ì„œ", "ê·¼ì²˜", "ì£¼ë³€", "ìš”ì¦˜",
            "ë›°ì–´ë†€ê³ ",  # í•„ìš”í•˜ë©´ ë¹¼ë„ ë¨(ëŸ¬ë‹ì´ë©´ ì‚´ë¦¬ê³  ì‹¶ì„ ìˆ˜ë„)
        }

        cleaned = []
        for k in keywords:
            if not k:
                continue
            w = str(k).strip()
            if len(w) < 2:
                continue
            if w in stop:
                continue
            cleaned.append(w)

        # âœ… ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
        seen = set()
        out = []
        for w in cleaned:
            if w not in seen:
                out.append(w)
                seen.add(w)
        return out

    def _is_near_me_phrase(self, q: str | None) -> bool:
        if not q:
            return False
        s = str(q).strip().lower()
        return ("ê·¼ì²˜" in s) or ("ì£¼ë³€" in s) or ("ì§‘" in s) or ("ë‚´ ê·¼ì²˜" in s)








